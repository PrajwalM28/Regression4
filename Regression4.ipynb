{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36034227-8a62-4b75-9241-69de8cafa505",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "###  What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19f5c5-6317-45cd-8401-6a57926039bb",
   "metadata": {},
   "source": [
    "- Lasso Regression is a regularization technique used in linear regression. It adds a penalty term to the ordinary least squares (OLS) objective function, which includes the sum of squared coefficients. The key difference from other regression techniques, such as OLS regression, is the penalty term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd88c7-0f50-4dfd-9f71-974b90765d96",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "### What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d26b50-2875-42f6-9b72-7f5f602ed8d8",
   "metadata": {},
   "source": [
    "- The main advantage of using Lasso Regression in feature selection is its ability to automatically select a subset of important features by driving the coefficients of less important features to zero. This helps in simplifying the model and reducing overfitting, especially when dealing with a large number of predictors. Lasso can be particularly useful when there is multicollinearity among the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a110a4-318f-49bf-be24-82dccda7344e",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "###  How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc5ec6-3d37-441e-8604-be0cdc569913",
   "metadata": {},
   "source": [
    "- The coefficients of a Lasso Regression model can be interpreted similarly to those in linear regression. However, due to the penalty term, some coefficients may be exactly zero, indicating that the corresponding predictors have been effectively excluded from the model. Non-zero coefficients indicate the strength and direction of the relationship between the predictor and the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd66e7-cdcd-4caf-b4e5-8c3bd44de9aa",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "### What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf522c-dc15-4ea3-9e08-5c562e11c3f0",
   "metadata": {},
   "source": [
    "- The main tuning parameter in Lasso Regression is λ, which controls the strength of the penalty term. A larger λ leads to stronger regularization and more coefficients being pushed to zero. The choice of λ involves a trade-off between model simplicity and accuracy. Cross-validation is often used to find the optimal λ value that balances this trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083599c-21a6-4cfe-93bf-423e516dec74",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "### Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4a670-d00e-4f1f-aa26-f142f7799741",
   "metadata": {},
   "source": [
    "- Lasso Regression is inherently a linear regression technique, so it's not suitable for capturing non-linear relationships between predictors and the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e2400-d0f4-426f-882a-73f6fe102e5a",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "### What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15852f-5dce-4a0a-8446-98759e102b11",
   "metadata": {},
   "source": [
    "- They differ in the type of penalty term used. Ridge Regression adds a penalty term proportional to the sum of squared coefficients, while Lasso Regression adds a penalty term proportional to the sum of absolute values of coefficients. The key distinction is that Ridge tends to shrink coefficients towards zero, but it rarely sets them exactly to zero, whereas Lasso has a tendency to result in sparse models by setting some coefficients exactly to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43076720-ef47-4729-81b4-3a5fc4b3c7de",
   "metadata": {},
   "source": [
    "# Q7.\n",
    "### Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5bd1a-9e0a-4a44-9d14-cf2360807478",
   "metadata": {},
   "source": [
    "- Yes, Lasso Regression can handle multicollinearity to some extent. Lasso Regression tends to select one of the correlated features and set the coefficients of others to zero, effectively performing automatic feature selection. This can mitigate the issues caused by multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eedaa4-94dc-47b4-8854-c4195a08c31b",
   "metadata": {},
   "source": [
    "# Q8.\n",
    "### How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6a698-b228-4b21-af64-503d7d8c5014",
   "metadata": {},
   "source": [
    "- The optimal value of the regularization parameter in Lasso Regression is typically chosen through cross-validation. The idea is to train the model on different subsets of the data and evaluate its performance using a metric like mean squared error (MSE) or another appropriate measure. The value of λ that minimizes the prediction error on a validation set is chosen as the optimal regularization parameter. Grid search or more advanced optimization algorithms can be used to efficiently search for the optimal λ over a predefined range of values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
